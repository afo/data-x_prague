{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On-Time Flight Performance with GraphFrames for Apache Spark\n",
    "This notebook provides an analysis of On-Time Flight Performance and Departure Delays data using GraphFrames for Apache Spark.  This notebook has been updated to use Apache Spark 2.0 and GraphFrames 0.3.\n",
    "* Original blog post: [On-Time Flight Performance with GraphFrames with Apache Spark Blog Post](https://databricks.com/blog/2016/03/16/on-time-flight-performance-with-graphframes-for-apache-spark.html)\n",
    "* Original Notebook: [On-Time Flight Performance with GraphFrames with Apache Spark Notebook](http://cdn2.hubspot.net/hubfs/438089/notebooks/Samples/Miscellaneous/On-Time_Flight_Performance.html)\n",
    "\n",
    "\n",
    "Source Data: \n",
    "* [OpenFlights: Airport, airline and route data](http://openflights.org/data.html)\n",
    "* [United States Department of Transportation: Bureau of Transportation Statistics (TranStats)](http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time)\n",
    " * Note, the data used here was extracted from the US DOT:BTS between 1/1/2014 and 3/31/2014*\n",
    "\n",
    "References:\n",
    "* [GraphFrames User Guide](http://graphframes.github.io/user-guide.html)\n",
    "* [GraphFrames: DataFrame-based Graphs (GitHub)](https://github.com/graphframes/graphframes)\n",
    "* [D3 Airports Example](http://mbostock.github.io/d3/talk/20111116/airports.html)\n",
    "* [MLlib and Machine Learning: Binary Classification](https://docs.databricks.com/spark/latest/mllib/binary-classification-mllib-pipelines.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "Extract the Airports and Departure Delays information from S3 / DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs ls /databricks-datasets/flights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set File Paths\n",
    "tripdelaysFilePath = \"/databricks-datasets/flights/departuredelays.csv\"\n",
    "airportsnaFilePath = \"/databricks-datasets/flights/airport-codes-na.txt\"\n",
    "\n",
    "# Obtain airports dataset\n",
    "airportsna = spark.read.csv(airportsnaFilePath, header='true', inferSchema='true', sep='\\t')\n",
    "airportsna.createOrReplaceTempView(\"airports_na\")\n",
    "\n",
    "# Obtain departure Delays data\n",
    "departureDelays = spark.read.csv(tripdelaysFilePath, header='true')\n",
    "departureDelays.createOrReplaceTempView(\"departureDelays\")\n",
    "departureDelays.cache()\n",
    "\n",
    "# Available IATA codes from the departuredelays sample dataset\n",
    "tripIATA = spark.sql(\"select distinct iata from (select distinct origin as iata from departureDelays union all select distinct destination as iata from departureDelays) a\")\n",
    "tripIATA.createOrReplaceTempView(\"tripIATA\")\n",
    "\n",
    "# Only include airports with atleast one trip from the departureDelays dataset\n",
    "airports = spark.sql(\"select f.IATA, f.City, f.State, f.Country from airports_na f join tripIATA t on t.IATA = f.IATA\")\n",
    "airports.createOrReplaceTempView(\"airports\")\n",
    "airports.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "departureDelays.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build `departureDelays_geo` DataFrame\n",
    "#  Obtain key attributes such as Date of flight, delays, distance, and airport information (Origin, Destination)  \n",
    "departureDelays_geo = spark.sql(\"select cast(f.date as int) as tripid, cast(concat(concat(concat(concat(concat(concat('2014-', concat(concat(substr(cast(f.date as string), 1, 2), '-')), substr(cast(f.date as string), 3, 2)), ' '), substr(cast(f.date as string), 5, 2)), ':'), substr(cast(f.date as string), 7, 2)), ':00') as timestamp) as `localdate`, cast(f.delay as int), cast(f.distance as int), f.origin as src, f.destination as dst, o.city as city_src, d.city as city_dst, o.state as state_src, d.state as state_dst from departuredelays f join airports o on o.iata = f.origin join airports d on d.iata = f.destination\") \n",
    "\n",
    "# Create Temporary View and cache\n",
    "departureDelays_geo.createOrReplaceTempView(\"departureDelays_geo\")\n",
    "departureDelays_geo.cache()\n",
    "\n",
    "# Count\n",
    "departureDelays_geo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the top 10 rows of the `departureDelays_geo` DataFrame\n",
    "departureDelays_geo.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using `display` to view the data\n",
    "display(departureDelays_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Graph\n",
    "Now that we've imported our data, we're going to need to build our graph. To do so we're going to do two things: we are going to build the structure of the vertices (or nodes) and we're going to build the structure of the edges. What's awesome about GraphFrames is that this process is incredibly simple. \n",
    "* Rename IATA airport code to **id** in the Vertices Table\n",
    "* Start and End airports to **src** and **dst** for the Edges Table (flights)\n",
    "\n",
    "These are required naming conventions for vertices and edges in GraphFrames as of the time of this writing (Feb. 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING:** If the graphframes package, required in the cell below, is not installed, follow the instructions [here](http://cdn2.hubspot.net/hubfs/438089/notebooks/help/Setup_graphframes_package.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, ensure you have already installed the GraphFrames spack-package\n",
    "from pyspark.sql.functions import *\n",
    "from graphframes import *\n",
    "\n",
    "# Create Vertices (airports) and Edges (flights)\n",
    "tripVertices = airports.withColumnRenamed(\"IATA\", \"id\").distinct()\n",
    "tripEdges = departureDelays_geo.select(\"tripid\", \"delay\", \"src\", \"dst\", \"city_dst\", \"state_dst\")\n",
    "\n",
    "# Cache Vertices and Edges\n",
    "tripEdges.cache()\n",
    "tripVertices.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertices\n",
    "#   The vertices of our graph are the airports\n",
    "display(tripVertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges\n",
    "#  The edges of our graph are the flights between airports\n",
    "display(tripEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build `tripGraph` GraphFrame\n",
    "#  This GraphFrame builds up on the vertices and edges based on our trips (flights)\n",
    "tripGraph = GraphFrame(tripVertices, tripEdges)\n",
    "\n",
    "# Build `tripGraphPrime` GraphFrame\n",
    "#   This graphframe contains a smaller subset of data to make it easier to display motifs and subgraphs (below)\n",
    "tripEdgesPrime = departureDelays_geo.select(\"tripid\", \"delay\", \"src\", \"dst\")\n",
    "tripGraphPrime = GraphFrame(tripVertices, tripEdgesPrime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Queries\n",
    "Let's start with a set of simple graph queries to understand flight performance and departure delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the number of airports and trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Airports: %d\" % tripGraph.vertices.count())\n",
    "print (\"Trips: %d\" % tripGraph.edges.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining the longest delay in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripGraph.edges.groupBy().max(\"delay\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the longest Delay\n",
    "longestDelay = tripGraph.edges.groupBy().max(\"delay\")\n",
    "display(longestDelay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining the number of delayed vs. on-time / early flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining number of on-time / early flights vs. delayed flights\n",
    "print (\"On-time / Early Flights: %d\" % tripGraph.edges.filter(\"delay <= 0\").count())\n",
    "print (\"Delayed Flights: %d\" % tripGraph.edges.filter(\"delay > 0\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What flights departing SEA are most likely to have significant delays\n",
    "Note, delay can be <= 0 meaning the flight left on time or early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripGraph.edges\\\n",
    "  .filter(\"src = 'SEA' and delay > 0\")\\\n",
    "  .groupBy(\"src\", \"dst\")\\\n",
    "  .avg(\"delay\")\\\n",
    "  .sort(desc(\"avg(delay)\"))\\\n",
    "  .show(5)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tripGraph.edges.filter(\"src = 'SEA' and delay > 0\").groupBy(\"src\", \"dst\").avg(\"delay\").sort(desc(\"avg(delay)\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What destinations tend to have delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After displaying tripDelays, use Plot Options to set `state_dst` as a Key.\n",
    "tripDelays = tripGraph.edges.filter(\"delay > 0\")\n",
    "display(tripDelays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What destinations tend to have significant delays departing from SEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# States with the longest cumulative delays (with individual delays > 100 minutes) (origin: Seattle)\n",
    "display(tripGraph.edges.filter(\"src = 'SEA' and delay > 100\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertex Degrees\n",
    "* `inDegrees`: Incoming connections to the airport\n",
    "* `outDegrees`: Outgoing connections from the airport \n",
    "* `degrees`: Total connections to and from the airport\n",
    "\n",
    "Reviewing the various properties of the property graph to understand the incoming and outgoing connections between airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degrees\n",
    "#  The number of degrees - the number of incoming and outgoing connections - for various airports within this sample dataset\n",
    "display(tripGraph.degrees.sort(desc(\"degree\")).limit(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inDegrees\n",
    "#  The number of degrees - the number of incoming connections - for various airports within this sample dataset\n",
    "display(tripGraph.inDegrees.sort(desc(\"inDegree\")).limit(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outDegrees\n",
    "#  The number of degrees - the number of outgoing connections - for various airports within this sample dataset\n",
    "display(tripGraph.outDegrees.sort(desc(\"outDegree\")).limit(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City / Flight Relationships through Motif Finding\n",
    "To more easily understand the complex relationship of city airports and their flights with each other, we can use motifs to find patterns of airports (i.e. vertices) connected by flights (i.e. edges). The result is a DataFrame in which the column names are given by the motif keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What delays might we blame on SFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tripGraphPrime to more easily display \n",
    "#   - The associated edge (ab, bc) relationships \n",
    "#   - With the different the city / airports (a, b, c) where SFO is the connecting city (b)\n",
    "#   - Ensuring that flight ab (i.e. the flight to SFO) occured before flight bc (i.e. flight leaving SFO)\n",
    "#   - Note, TripID was generated based on time in the format of MMDDHHMM converted to int\n",
    "#       - Therefore bc.tripid < ab.tripid + 10000 means the second flight (bc) occured within approx a day of the first flight (ab)\n",
    "# Note: In reality, we would need to be more careful to link trips ab and bc.\n",
    "motifs = tripGraphPrime.find(\"(a)-[ab]->(b); (b)-[bc]->(c)\")\\\n",
    "  .filter(\"(b.id = 'SFO') and (ab.delay > 500 or bc.delay > 500) and bc.tripid > ab.tripid and bc.tripid < ab.tripid + 10000\")\n",
    "display(motifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Airport Ranking using PageRank\n",
    "There are a large number of flights and connections through these various airports included in this Departure Delay Dataset.  Using the `pageRank` algorithm, Spark iteratively traverses the graph and determines a rough estimate of how important the airport is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining Airport ranking of importance using `pageRank`\n",
    "ranks = tripGraph.pageRank(resetProbability=0.15, maxIter=5)\n",
    "display(ranks.vertices.orderBy(ranks.vertices.pagerank.desc()).limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most popular flights (single city hops)\n",
    "Using the `tripGraph`, we can quickly determine what are the most popular single city hop flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the most popular flights (single city hops)\n",
    "import pyspark.sql.functions as func\n",
    "topTrips = tripGraph \\\n",
    "  .edges \\\n",
    "  .groupBy(\"src\", \"dst\") \\\n",
    "  .agg(func.count(\"delay\").alias(\"trips\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the top 20 most popular flights (single city hops)\n",
    "display(topTrips.orderBy(topTrips.trips.desc()).limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Transfer Cities\n",
    "Many airports are used as transfer points instead of the final Destination.  An easy way to calculate this is by calculating the ratio of inDegree (the number of flights to the airport) / outDegree (the number of flights leaving the airport).  Values close to 1 may indicate many transfers, whereas values < 1 indicate many outgoing flights and > 1 indicate many incoming flights.  Note, this is a simple calculation that does not take into account of timing or scheduling of flights, just the overall aggregate number within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the inDeg (flights into the airport) and outDeg (flights leaving the airport)\n",
    "inDeg = tripGraph.inDegrees\n",
    "outDeg = tripGraph.outDegrees\n",
    "\n",
    "# Calculate the degreeRatio (inDeg/outDeg)\n",
    "degreeRatio = inDeg.join(outDeg, inDeg.id == outDeg.id) \\\n",
    "  .drop(outDeg.id) \\\n",
    "  .selectExpr(\"id\", \"double(inDegree)/double(outDegree) as degreeRatio\") \\\n",
    "  .cache()\n",
    "\n",
    "# Join back to the `airports` DataFrame (instead of registering temp table as above)\n",
    "nonTransferAirports = degreeRatio.join(airports, degreeRatio.id == airports.IATA) \\\n",
    "  .selectExpr(\"id\", \"city\", \"degreeRatio\") \\\n",
    "  .filter(\"degreeRatio < .9 or degreeRatio > 1.1\")\n",
    "\n",
    "# List out the city airports which have abnormal degree ratios.\n",
    "display(nonTransferAirports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join back to the `airports` DataFrame (instead of registering temp table as above)\n",
    "transferAirports = degreeRatio.join(airports, degreeRatio.id == airports.IATA) \\\n",
    "  .selectExpr(\"id\", \"city\", \"degreeRatio\") \\\n",
    "  .filter(\"degreeRatio between 0.9 and 1.1\")\n",
    "  \n",
    "# List out the top 10 transfer city airports\n",
    "display(transferAirports.orderBy(\"degreeRatio\").limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breadth First Search \n",
    "Breadth-first search (BFS) is designed to traverse the graph to quickly find the desired vertices (i.e. airports) and edges (i.e flights).  Let's try to find the shortest number of connections between cities based on the dataset.  Note, these examples do not take into account of time or distance, just hops between cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Direct Seattle to San Francisco \n",
    "filteredPaths = tripGraph.bfs(\n",
    "  fromExpr = \"id = 'SEA'\",\n",
    "  toExpr = \"id = 'SFO'\",\n",
    "  maxPathLength = 1)\n",
    "display(filteredPaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are a number of direct flights between Seattle and San Francisco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Direct San Francisco and Buffalo\n",
    "filteredPaths = tripGraph.bfs(\n",
    "  fromExpr = \"id = 'SFO'\",\n",
    "  toExpr = \"id = 'BUF'\",\n",
    "  maxPathLength = 2)\n",
    "display(filteredPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display most popular layover cities by descending count\n",
    "display(filteredPaths.groupBy(\"v1.id\", \"v1.City\").count().orderBy(desc(\"count\")).limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Direct San Francisco and Buffalo\n",
    "filteredPaths = tripGraph.bfs(\n",
    "  fromExpr = \"id = 'SFO'\",\n",
    "  toExpr = \"id = 'BUF'\",\n",
    "  maxPathLength = 1)\n",
    "display(filteredPaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are no direct flights between San Francisco and Buffalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2a: Flying from San Francisco to Buffalo\n",
    "filteredPaths = tripGraph.bfs(\n",
    "  fromExpr = \"id = 'SFO'\",\n",
    "  toExpr = \"id = 'BUF'\",\n",
    "  maxPathLength = 2)\n",
    "display(filteredPaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are flights from San Francisco to Buffalo with Minneapolis as the transfer point.  But what are the most popular layovers between `SFO` and `BUF`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display most popular layover cities by descending count\n",
    "display(filteredPaths.groupBy(\"v1.id\", \"v1.City\").count().orderBy(desc(\"count\")).limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the D3 Visualization\n",
    "Using the airports D3 visualization to visualize airports and flight paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%scala\n",
    "package d3a\n",
    "// We use a package object so that we can define top level classes like Edge that need to be used in other cells\n",
    "\n",
    "import org.apache.spark.sql._\n",
    "import com.databricks.backend.daemon.driver.EnhancedRDDFunctions.displayHTML\n",
    "\n",
    "case class Edge(src: String, dest: String, count: Long)\n",
    "\n",
    "case class Node(name: String)\n",
    "case class Link(source: Int, target: Int, value: Long)\n",
    "case class Graph(nodes: Seq[Node], links: Seq[Link])\n",
    "\n",
    "object graphs {\n",
    "val sqlContext = SQLContext.getOrCreate(org.apache.spark.SparkContext.getOrCreate())\n",
    "import sqlContext.implicits._\n",
    "\n",
    "def force(clicks: Dataset[Edge], height: Int = 100, width: Int = 960): Unit = {\n",
    "  val data = clicks.collect()\n",
    "  val nodes = (data.map(_.src) ++ data.map(_.dest)).map(_.replaceAll(\"_\", \" \")).toSet.toSeq.map(Node)\n",
    "  val links = data.map { t =>\n",
    "    Link(nodes.indexWhere(_.name == t.src.replaceAll(\"_\", \" \")), nodes.indexWhere(_.name == t.dest.replaceAll(\"_\", \" \")), t.count / 20 + 1)\n",
    "  }\n",
    "  showGraph(height, width, Seq(Graph(nodes, links)).toDF().toJSON.first())\n",
    "}\n",
    "\n",
    "/**\n",
    " * Displays a force directed graph using d3\n",
    " * input: {\"nodes\": [{\"name\": \"...\"}], \"links\": [{\"source\": 1, \"target\": 2, \"value\": 0}]}\n",
    " */\n",
    "def showGraph(height: Int, width: Int, graph: String): Unit = {\n",
    "\n",
    "displayHTML(s\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <link type=\"text/css\" rel=\"stylesheet\" href=\"https://mbostock.github.io/d3/talk/20111116/style.css\"/>\n",
    "    <style type=\"text/css\">\n",
    "      #states path {\n",
    "        fill: #ccc;\n",
    "        stroke: #fff;\n",
    "      }\n",
    "\n",
    "      path.arc {\n",
    "        pointer-events: none;\n",
    "        fill: none;\n",
    "        stroke: #000;\n",
    "        display: none;\n",
    "      }\n",
    "\n",
    "      path.cell {\n",
    "        fill: none;\n",
    "        pointer-events: all;\n",
    "      }\n",
    "\n",
    "      circle {\n",
    "        fill: steelblue;\n",
    "        fill-opacity: .8;\n",
    "        stroke: #fff;\n",
    "      }\n",
    "\n",
    "      #cells.voronoi path.cell {\n",
    "        stroke: brown;\n",
    "      }\n",
    "\n",
    "      #cells g:hover path.arc {\n",
    "        display: inherit;\n",
    "      }\n",
    "    </style>\n",
    "  </head>\n",
    "  <body>\n",
    "    <script src=\"https://mbostock.github.io/d3/talk/20111116/d3/d3.js\"></script>\n",
    "    <script src=\"https://mbostock.github.io/d3/talk/20111116/d3/d3.csv.js\"></script>\n",
    "    <script src=\"https://mbostock.github.io/d3/talk/20111116/d3/d3.geo.js\"></script>\n",
    "    <script src=\"https://mbostock.github.io/d3/talk/20111116/d3/d3.geom.js\"></script>\n",
    "    <script>\n",
    "      var graph = $graph;\n",
    "      var w = $width;\n",
    "      var h = $height;\n",
    "\n",
    "      var linksByOrigin = {};\n",
    "      var countByAirport = {};\n",
    "      var locationByAirport = {};\n",
    "      var positions = [];\n",
    "\n",
    "      var projection = d3.geo.azimuthal()\n",
    "          .mode(\"equidistant\")\n",
    "          .origin([-98, 38])\n",
    "          .scale(1400)\n",
    "          .translate([640, 360]);\n",
    "\n",
    "      var path = d3.geo.path()\n",
    "          .projection(projection);\n",
    "\n",
    "      var svg = d3.select(\"body\")\n",
    "          .insert(\"svg:svg\", \"h2\")\n",
    "          .attr(\"width\", w)\n",
    "          .attr(\"height\", h);\n",
    "\n",
    "      var states = svg.append(\"svg:g\")\n",
    "          .attr(\"id\", \"states\");\n",
    "\n",
    "      var circles = svg.append(\"svg:g\")\n",
    "          .attr(\"id\", \"circles\");\n",
    "\n",
    "      var cells = svg.append(\"svg:g\")\n",
    "          .attr(\"id\", \"cells\");\n",
    "\n",
    "      var arc = d3.geo.greatArc()\n",
    "          .source(function(d) { return locationByAirport[d.source]; })\n",
    "          .target(function(d) { return locationByAirport[d.target]; });\n",
    "\n",
    "      d3.select(\"input[type=checkbox]\").on(\"change\", function() {\n",
    "        cells.classed(\"voronoi\", this.checked);\n",
    "      });\n",
    "\n",
    "      // Draw US map.\n",
    "      d3.json(\"https://mbostock.github.io/d3/talk/20111116/us-states.json\", function(collection) {\n",
    "        states.selectAll(\"path\")\n",
    "          .data(collection.features)\n",
    "          .enter().append(\"svg:path\")\n",
    "          .attr(\"d\", path);\n",
    "      });\n",
    "\n",
    "      // Parse links\n",
    "      graph.links.forEach(function(link) {\n",
    "        var origin = graph.nodes[link.source].name;\n",
    "        var destination = graph.nodes[link.target].name;\n",
    "\n",
    "        var links = linksByOrigin[origin] || (linksByOrigin[origin] = []);\n",
    "        links.push({ source: origin, target: destination });\n",
    "\n",
    "        countByAirport[origin] = (countByAirport[origin] || 0) + 1;\n",
    "        countByAirport[destination] = (countByAirport[destination] || 0) + 1;\n",
    "      });\n",
    "\n",
    "      d3.csv(\"https://mbostock.github.io/d3/talk/20111116/airports.csv\", function(data) {\n",
    "\n",
    "        // Build list of airports.\n",
    "        var airports = graph.nodes.map(function(node) {\n",
    "          return data.find(function(airport) {\n",
    "            if (airport.iata === node.name) {\n",
    "              var location = [+airport.longitude, +airport.latitude];\n",
    "              locationByAirport[airport.iata] = location;\n",
    "              positions.push(projection(location));\n",
    "\n",
    "              return true;\n",
    "            } else {\n",
    "              return false;\n",
    "            }\n",
    "          });\n",
    "        });\n",
    "\n",
    "        // Compute the Voronoi diagram of airports' projected positions.\n",
    "        var polygons = d3.geom.voronoi(positions);\n",
    "\n",
    "        var g = cells.selectAll(\"g\")\n",
    "            .data(airports)\n",
    "          .enter().append(\"svg:g\");\n",
    "\n",
    "        g.append(\"svg:path\")\n",
    "            .attr(\"class\", \"cell\")\n",
    "            .attr(\"d\", function(d, i) { return \"M\" + polygons[i].join(\"L\") + \"Z\"; })\n",
    "            .on(\"mouseover\", function(d, i) { d3.select(\"h2 span\").text(d.name); });\n",
    "\n",
    "        g.selectAll(\"path.arc\")\n",
    "            .data(function(d) { return linksByOrigin[d.iata] || []; })\n",
    "          .enter().append(\"svg:path\")\n",
    "            .attr(\"class\", \"arc\")\n",
    "            .attr(\"d\", function(d) { return path(arc(d)); });\n",
    "\n",
    "        circles.selectAll(\"circle\")\n",
    "            .data(airports)\n",
    "            .enter().append(\"svg:circle\")\n",
    "            .attr(\"cx\", function(d, i) { return positions[i][0]; })\n",
    "            .attr(\"cy\", function(d, i) { return positions[i][1]; })\n",
    "            .attr(\"r\", function(d, i) { return Math.sqrt(countByAirport[d.iata]); })\n",
    "            .sort(function(a, b) { return countByAirport[b.iata] - countByAirport[a.iata]; });\n",
    "      });\n",
    "    </script>\n",
    "  </body>\n",
    "</html>\"\"\")\n",
    "  }\n",
    "\n",
    "  def help() = {\n",
    "displayHTML(\"\"\"\n",
    "<p>\n",
    "Produces a force-directed graph given a collection of edges of the following form:</br>\n",
    "<tt><font color=\"#a71d5d\">case class</font> <font color=\"#795da3\">Edge</font>(<font color=\"#ed6a43\">src</font>: <font color=\"#a71d5d\">String</font>, <font color=\"#ed6a43\">dest</font>: <font color=\"#a71d5d\">String</font>, <font color=\"#ed6a43\">count</font>: <font color=\"#a71d5d\">Long</font>)</tt>\n",
    "</p>\n",
    "<p>Usage:<br/>\n",
    "<tt>%scala</tt></br>\n",
    "<tt><font color=\"#a71d5d\">import</font> <font color=\"#ed6a43\">d3._</font></tt><br/>\n",
    "<tt><font color=\"#795da3\">graphs.force</font>(</br>\n",
    "&nbsp;&nbsp;<font color=\"#ed6a43\">height</font> = <font color=\"#795da3\">500</font>,<br/>\n",
    "&nbsp;&nbsp;<font color=\"#ed6a43\">width</font> = <font color=\"#795da3\">500</font>,<br/>\n",
    "&nbsp;&nbsp;<font color=\"#ed6a43\">clicks</font>: <font color=\"#795da3\">Dataset</font>[<font color=\"#795da3\">Edge</font>])</tt>\n",
    "</p>\"\"\")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%scala d3a.graphs.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize On-time and Early Arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%scala\n",
    "// On-time and Early Arrivals\n",
    "import d3a._\n",
    "graphs.force(\n",
    "  height = 800,\n",
    "  width = 1200,\n",
    "  clicks = sql(\"\"\"select src, dst as dest, count(1) as count from departureDelays_geo where delay <= 0 group by src, dst\"\"\").as[Edge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Delayed Trips Departing from the West Coast\n",
    "\n",
    "Notice that most of the delayed trips are with Western US cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%scala\n",
    "// Delayed Trips from CA, OR, and/or WA\n",
    "import d3a._\n",
    "graphs.force(\n",
    "  height = 800,\n",
    "  width = 1200,\n",
    "  clicks = sql(\"\"\"select src, dst as dest, count(1) as count from departureDelays_geo where state_src in ('CA', 'OR', 'WA') and delay > 0 group by src, dst\"\"\").as[Edge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize All Flights (from this dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%scala\n",
    "// Trips (from DepartureDelays Dataset)\n",
    "import d3a._\n",
    "graphs.force(\n",
    "  height = 800,\n",
    "  width = 1200,\n",
    "  clicks = sql(\"\"\"select src, dst as dest, count(1) as count from departureDelays_geo group by src, dst\"\"\").as[Edge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Flight Delays\n",
    "Extending upon analysis we have done up to this point, can we also predict if a flight will be delayed, on-time, or early based on the available data.\n",
    "\n",
    "### Prepare the Dataset\n",
    "The first thing we will do is to cleanse the data and apply some labels to our information (e.g. early, on-time, delayed).  As well, we will want to remove any rows with NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This contains a generated mapping between tripid and airline\n",
    "#   You can get the file at https://github.com/dennyglee/databricks/blob/master/misc/trip_airline_map.csv\n",
    "#   For this example, the trip_airline_map.csv file has been pushed to in my mounted bucket.\n",
    "tripAirlineMap = spark.read.csv(\"/mnt/tardis6/departuredelays/trip_airline_map.csv\", sep=\",\", header=True)\n",
    "tripAirlineMap.createOrReplaceTempView(\"tripAirlineMap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep dataset\n",
    "# Limiting to only Las Vegas (LAS) and Seattle (SEA) predictions so it can run on Databricks Community Edition\n",
    "flightML = spark.sql(\"select cast(distance as double) as distance, src as origin, state_src as origin_state, dst as destination, state_dst as destination_state, concat(concat(concat(cast(tripid as string), src), dst), cast((delay + 2000) as string)) as trip_identifier, case when delay <= 0 then 'on-time' else 'delayed' end as flight_status from departureDelays_geo where src in ('LAS', 'SEA')\")\n",
    "flightML = flightML.dropna().dropDuplicates()\n",
    "flightML.createOrReplaceTempView(\"flightML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join flights and airline information\n",
    "dataset = spark.sql(\"select f.distance, f.origin, f.origin_state, f.destination, f.destination_state, f.trip_identifier, f.flight_status, m.airline from flightML f join tripAirlineMap m on m.trip_identifier = f.trip_identifier\")\n",
    "dataset = dataset.dropDuplicates()\n",
    "#dataset = flightML\n",
    "cols = dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building ML Pipeline\n",
    "Before we can run our various models against this data, we will first need to vectorize our data via One-Hot Encorder (for category data), String Indexer (create an index based on our labelled values), and Vector Assembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "categoricalColumns = [\"origin\", \"origin_state\", \"destination\", \"destination_state\", \"trip_identifier\", \"airline\"]\n",
    "#categoricalColumns = [\"origin\", \"origin_state\", \"destination\", \"destination_state\", \"trip_identifier\"]\n",
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in categoricalColumns:\n",
    "  # Category Indexing with StringIndexer\n",
    "  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n",
    "  \n",
    "  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n",
    "  \n",
    "  # Add stages.  These are not run here, but will run all at once later on.\n",
    "  stages += [stringIndexer, encoder]\n",
    "\n",
    "# Convert label into label indices using the StringIndexer\n",
    "label_stringIdx = StringIndexer(inputCol = \"flight_status\", outputCol = \"label\")\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "# Transform all features into a vector using VectorAssembler\n",
    "numericCols = [\"distance\"]\n",
    "assemblerInputs = map(lambda c: c + \"classVec\", categoricalColumns) + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=stages)\n",
    "# Run the feature transformations.\n",
    "#  - fit() computes feature statistics as needed.\n",
    "#  - transform() actually transforms the features.\n",
    "pipelineModel = pipeline.fit(dataset)\n",
    "dataset = pipelineModel.transform(dataset)\n",
    "\n",
    "# Keep relevant columns\n",
    "selectedcols = [\"label\", \"features\"] + cols\n",
    "dataset = dataset.select(selectedcols)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly split data into training and test datasets\n",
    "* Set the seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "print trainingData.count()\n",
    "print testData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Let's try using logistic regression to see if we can accurately predict if a flight will be delayed.\n",
    "* First, we will train the data using Logistic Regression\n",
    "* Next we will run that model against the testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the transform() method.\n",
    "# LogisticRegression.transform() will only use the 'features' column.\n",
    "predictions = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View LR Model's predictions\n",
    "* Recall, label is the actual test value, prediction is the predicted value\n",
    " * where 0 - on-time, 1 - delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"flight_status\", \"destination\", \"destination_state\").where(\"destination = 'SEA'\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate our model\n",
    "Let's use the `BinaryClassificationEvaluator` to determine the precision of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "name": "On-Time Flight Performance (Spark 2.0)",
  "notebookId": 3083346632044008
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
