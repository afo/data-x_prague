{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Population vs. Median Home Prices\n",
    "#### *Linear Regression with Single Variable*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note, this notebook requires Spark 2.0+* , check done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%scala if (org.apache.spark.BuildInfo.sparkBranch < \"2.0\") sys.error(\"Attach this notebook to a cluster running Spark 2.0+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and parse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Spark CSV datasource with options specifying:\n",
    "#  - First line of file is a header\n",
    "#  - Automatically infer the schema of the data\n",
    "#  - Note that we're using `spark` instead of `sqlContext` now.\n",
    "data = spark.read.format(\"com.databricks.spark.csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"/databricks-datasets/samples/population-vs-price/data_geo.csv\")\n",
    "data.cache()  # Cache data for faster reuse\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()  # drop rows with missing values\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will let us access the table from sqlContext\n",
    "data.createOrReplaceTempView(\"data_geo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select City, `State Code`, `2014 Population estimate`/1000 as `2014 Pop estimate`, `2015 median sales price` from data_geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot and group by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select `State Code`, AVG(`2015 median sales price`) from data_geo GROUP BY `State Code`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit data to Population vs. Price\n",
    "(for our ML example)\n",
    "\n",
    "We also use VectorAssembler to put this together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with just the data we want to run linear regression\n",
    "df = spark.sql(\"select `2014 Population estimate`, `2015 median sales price` as label from data_geo\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"2014 Population estimate\"],\n",
    "    outputCol=\"features\")\n",
    "output = assembler.transform(df)\n",
    "display(output.select(\"features\", \"label\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "**Goal**\n",
    "* Predict y = 2015 Median Housing Price\n",
    "* Using feature x = 2014 Population Estimate\n",
    "\n",
    "**References**\n",
    "* [MLlib LinearRegression user guide](http://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression)\n",
    "* [PySpark LinearRegression API](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.regression.LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Define LinearRegression algorithm\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit 2 models, using different regularization parameters\n",
    "modelA = lr.fit(output, {lr.regParam:0.0})\n",
    "modelB = lr.fit(output, {lr.regParam:100.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \">>>> ModelA intercept: %r, coefficient: %r\" % (modelA.intercept, modelA.coefficients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \">>>> ModelB intercept: %r, coefficient: %r\" % (modelB.intercept, modelB.coefficients[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "\n",
    "Calling `transform()` on data adds a new column of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictionsA = modelA.transform(output)\n",
    "display(predictionsA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "#### Predicted vs. True label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\")\n",
    "RMSE = evaluator.evaluate(predictionsA)\n",
    "print(\"ModelA: Root Mean Squared Error = \" + str(RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsB = modelB.transform(output)\n",
    "RMSE = evaluator.evaluate(predictionsB)\n",
    "print(\"ModelB: Root Mean Squared Error = \" + str(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import *\n",
    "from ggplot import *\n",
    "\n",
    "pop = output.rdd.map(lambda p: (p.features[0])).collect()\n",
    "price = output.rdd.map(lambda p: (p.label)).collect()\n",
    "predA = predictionsA.select(\"prediction\").rdd.map(lambda r: r[0]).collect()\n",
    "predB = predictionsB.select(\"prediction\").rdd.map(lambda r: r[0]).collect()\n",
    "\n",
    "pydf = DataFrame({'pop':pop,'price':price,'predA':predA, 'predB':predB})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Python Pandas DataFrame (pydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ggplot figure\n",
    "Now that the Python Pandas DataFrame (pydf), use ggplot and display the scatterplot and the two regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ggplot(pydf, aes('pop','price')) + \\\n",
    "    geom_point(color='blue') + \\\n",
    "    geom_line(pydf, aes('pop','predA'), color='red') + \\\n",
    "    geom_line(pydf, aes('pop','predB'), color='green') + \\\n",
    "    scale_x_log10() + scale_y_log10()\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "name": "Pop. vs. Price LR 2.0",
  "notebookId": 3486959726874191
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
