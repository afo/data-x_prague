{"cells":[{"cell_type":"markdown","source":["## Use Keras with TensorFlow on a single node\n\nThis notebook demonstrates how to use Keras (with TensorFlow in the backend) on the Spark driver node to fit a neural network on MNIST handwritten digit recognition data.\n\nNote that this does not utilize any parallelizatin benefits or GPU benefits. That can easily be included, but we are running on Databricks Community edition so it is not feasible.\n\nThe content of this notebook is [copied from the Keras project](https://github.com/fchollet/keras/blob/47350dc6078053403c59e8da3fd63ac3ae12b5ec/examples/mnist_cnn.py) under the [MIT license](https://github.com/fchollet/keras/blob/47350dc6078053403c59e8da3fd63ac3ae12b5ec/LICENSE) with slight modifications in comments. Thanks to the developers of Keras for this example!"],"metadata":{}},{"cell_type":"markdown","source":["### Handwritten Digit Recognition\n\nThis tutorial guides you through a classic computer vision application: identify hand written digits with neural networks. \nWe will train a simple Convolutional Neural Network on the MNIST dataset.\n\nNote that we will not explicitly choose a backend for Keras, so it will use TensorFlow by default."],"metadata":{}},{"cell_type":"code","source":["from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["### Load and process data\n\nWe first fetch the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, which is a commonly used dataset for handwritten digit recognition. Keras provides a handy function for loading this data."],"metadata":{}},{"cell_type":"code","source":["# the data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# input image dimensions\nimg_rows, img_cols = 28, 28\n# number of classes (digits) to predict\nnum_classes = 10\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["### Train a CNN model"],"metadata":{}},{"cell_type":"markdown","source":["First, define the model structure."],"metadata":{}},{"cell_type":"code","source":["model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["Now, we can fit the model.  This should take about 10-15 seconds per epoch on a commodity GPU, or about 2-3 minutes for 12 epochs."],"metadata":{}},{"cell_type":"code","source":["batch_size = 128\nepochs = 2\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["### Evaluate the model\n\nWe can get test accuracy above `95%` after 12 epochs, but there is still a lot of margin for improvements via parameter tuning."],"metadata":{}},{"cell_type":"code","source":["score = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])"],"metadata":{},"outputs":[],"execution_count":13}],"metadata":{"name":"Keras-single-node","notebookId":1515220293376038},"nbformat":4,"nbformat_minor":0}
